{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100 #전체 데이터를 50번 학습하겠다\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "#cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\syr01\\venv\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 4.724900255\n",
      "Epoch: 0002 cost = 1.821572741\n",
      "Epoch: 0003 cost = 1.230543995\n",
      "Epoch: 0004 cost = 0.971414856\n",
      "Epoch: 0005 cost = 0.829687539\n",
      "Epoch: 0006 cost = 0.731941199\n",
      "Epoch: 0007 cost = 0.666578815\n",
      "Epoch: 0008 cost = 0.615258187\n",
      "Epoch: 0009 cost = 0.575391748\n",
      "Epoch: 0010 cost = 0.541400381\n",
      "Epoch: 0011 cost = 0.518330914\n",
      "Epoch: 0012 cost = 0.494121116\n",
      "Epoch: 0013 cost = 0.472597466\n",
      "Epoch: 0014 cost = 0.459994446\n",
      "Epoch: 0015 cost = 0.444037212\n",
      "Epoch: 0016 cost = 0.428034122\n",
      "Epoch: 0017 cost = 0.419236120\n",
      "Epoch: 0018 cost = 0.407895587\n",
      "Epoch: 0019 cost = 0.398795729\n",
      "Epoch: 0020 cost = 0.390544424\n",
      "Epoch: 0021 cost = 0.380626910\n",
      "Epoch: 0022 cost = 0.377057470\n",
      "Epoch: 0023 cost = 0.365099561\n",
      "Epoch: 0024 cost = 0.360828218\n",
      "Epoch: 0025 cost = 0.354417762\n",
      "Epoch: 0026 cost = 0.351973138\n",
      "Epoch: 0027 cost = 0.342591744\n",
      "Epoch: 0028 cost = 0.342317738\n",
      "Epoch: 0029 cost = 0.332668671\n",
      "Epoch: 0030 cost = 0.332060926\n",
      "Epoch: 0031 cost = 0.326632118\n",
      "Epoch: 0032 cost = 0.325820644\n",
      "Epoch: 0033 cost = 0.317064975\n",
      "Epoch: 0034 cost = 0.316575340\n",
      "Epoch: 0035 cost = 0.314674965\n",
      "Epoch: 0036 cost = 0.311433139\n",
      "Epoch: 0037 cost = 0.305004652\n",
      "Epoch: 0038 cost = 0.305509521\n",
      "Epoch: 0039 cost = 0.302185682\n",
      "Epoch: 0040 cost = 0.299569689\n",
      "Epoch: 0041 cost = 0.299118917\n",
      "Epoch: 0042 cost = 0.296002865\n",
      "Epoch: 0043 cost = 0.290701897\n",
      "Epoch: 0044 cost = 0.291046886\n",
      "Epoch: 0045 cost = 0.286790909\n",
      "Epoch: 0046 cost = 0.290638349\n",
      "Epoch: 0047 cost = 0.284949255\n",
      "Epoch: 0048 cost = 0.282548380\n",
      "Epoch: 0049 cost = 0.283209524\n",
      "Epoch: 0050 cost = 0.279158555\n",
      "Epoch: 0051 cost = 0.277390005\n",
      "Epoch: 0052 cost = 0.279762587\n",
      "Epoch: 0053 cost = 0.275237054\n",
      "Epoch: 0054 cost = 0.274350702\n",
      "Epoch: 0055 cost = 0.274048963\n",
      "Epoch: 0056 cost = 0.270566598\n",
      "Epoch: 0057 cost = 0.270095416\n",
      "Epoch: 0058 cost = 0.267336573\n",
      "Epoch: 0059 cost = 0.269247739\n",
      "Epoch: 0060 cost = 0.269332872\n",
      "Epoch: 0061 cost = 0.263748510\n",
      "Epoch: 0062 cost = 0.264593349\n",
      "Epoch: 0063 cost = 0.263712504\n",
      "Epoch: 0064 cost = 0.261381074\n",
      "Epoch: 0065 cost = 0.263897142\n",
      "Epoch: 0066 cost = 0.261264500\n",
      "Epoch: 0067 cost = 0.259699238\n",
      "Epoch: 0068 cost = 0.258659083\n",
      "Epoch: 0069 cost = 0.257427540\n",
      "Epoch: 0070 cost = 0.259865934\n",
      "Epoch: 0071 cost = 0.253703784\n",
      "Epoch: 0072 cost = 0.257974718\n",
      "Epoch: 0073 cost = 0.253481665\n",
      "Epoch: 0074 cost = 0.256201749\n",
      "Epoch: 0075 cost = 0.252854667\n",
      "Epoch: 0076 cost = 0.253454110\n",
      "Epoch: 0077 cost = 0.252655988\n",
      "Epoch: 0078 cost = 0.252323972\n",
      "Epoch: 0079 cost = 0.248036711\n",
      "Epoch: 0080 cost = 0.251125582\n",
      "Epoch: 0081 cost = 0.248069608\n",
      "Epoch: 0082 cost = 0.251545593\n",
      "Epoch: 0083 cost = 0.245992321\n",
      "Epoch: 0084 cost = 0.250358313\n",
      "Epoch: 0085 cost = 0.246829769\n",
      "Epoch: 0086 cost = 0.245816585\n",
      "Epoch: 0087 cost = 0.244881153\n",
      "Epoch: 0088 cost = 0.245043559\n",
      "Epoch: 0089 cost = 0.247508089\n",
      "Epoch: 0090 cost = 0.243286535\n",
      "Epoch: 0091 cost = 0.243621215\n",
      "Epoch: 0092 cost = 0.243243058\n",
      "Epoch: 0093 cost = 0.245135688\n",
      "Epoch: 0094 cost = 0.236548878\n",
      "Epoch: 0095 cost = 0.246309957\n",
      "Epoch: 0096 cost = 0.240111029\n",
      "Epoch: 0097 cost = 0.242082034\n",
      "Epoch: 0098 cost = 0.240034544\n",
      "Epoch: 0099 cost = 0.243533212\n",
      "Epoch: 0100 cost = 0.238207112\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'bool'>\n",
      "Accuracy: 0.9218\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# 정확도 확인하기\n",
    "# Test model and check accuracy\n",
    "pred = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "print (pred.dtype)\n",
    "accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
